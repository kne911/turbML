{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2b\n",
    "2b Instead of using Neural Network, NN (Python’s pytorch) use Random Forest, RF (Python’s RandomForestRegress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from LoadData import *\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch \n",
    "import sys \n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from random import randrange\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.interactive(True)\n",
    "plt.close('all')\n",
    "# Create output path\n",
    "outputPath = 'Output/'\n",
    "Path(\"Output\").mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully developed plane turbulent channel flow $Re=5200$\n",
    "\n",
    "For training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning data from: FullyDevelopedChannel_Re5200. Min yplus: 20. Max yplus: 2200\n",
      "Returning c = [c0, c2], a11 and a33\n",
      "time ML: 7.52e-01\n",
      "\n",
      "c0_error_std:  0.0006779127266866799\n",
      "\n",
      "c2_error_std:  0.0010142991828608328\n"
     ]
    }
   ],
   "source": [
    "y_DNS, yplus_DNS, u_DNS, uu_DNS, vv_DNS, ww_DNS, uv_DNS, k_DNS, eps_DNS, dudy_DNS = GetInputData('FullyDevelopedChannel_Re5200', 20, 2200)\n",
    "c, a11_DNS, a33_DNS = GetC0andC2(k_DNS, eps_DNS, dudy_DNS, uu_DNS, vv_DNS, ww_DNS)\n",
    "\n",
    "# transpose the target vector to make it a column vector  \n",
    "y = c.transpose()\n",
    "tau_DNS = abs(k_DNS/eps_DNS)\n",
    "dudy_squared_DNS = (dudy_DNS**2)\n",
    "viscous_t = k_DNS**2/eps_DNS \n",
    "nu = 8.00000e-06\n",
    "\n",
    "T = tau_DNS\n",
    "dudy_squared_DNS_scaled = dudy_squared_DNS*T**2\n",
    "dudy_DNS_inv = 1/dudy_DNS/T\n",
    "viscous_t_plus= viscous_t/nu\n",
    "\n",
    "dudy_squared_DNS_scaled = dudy_squared_DNS_scaled.reshape(-1,1)\n",
    "dudy_DNS_inv_scaled = dudy_DNS_inv.reshape(-1,1)\n",
    "yplus_DNS_scaled = yplus_DNS.reshape(-1,1)\n",
    "viscous_scaled = viscous_t_plus.reshape(-1,1)\n",
    "scaler_dudy2 = MinMaxScaler()\n",
    "scaler_dudy = MinMaxScaler()\n",
    "scaler_yplus = MinMaxScaler()\n",
    "scaler_visc = MinMaxScaler()\n",
    "\n",
    "X=np.zeros((len(dudy_DNS),2))\n",
    "X[:,0] = scaler_dudy2.fit_transform(dudy_squared_DNS_scaled)[:,0]\n",
    "#X[:,1] = scaler_dudy.fit_transform(dudy_DNS_inv_scaled)[:,0]\n",
    "X[:,1] = scaler_yplus.fit_transform(yplus_DNS_scaled)[:,0]\n",
    "#X[:,2] = scaler_visc.fit_transform(viscous_scaled)[:,0]\n",
    "\n",
    "random_state = randrange(100)\n",
    "indices = np.arange(len(X))\n",
    "X_train, X_test, y_train, y_test, index_train, index_test = train_test_split(X, y, indices,test_size = 0.1 ,shuffle=True,random_state=42)\n",
    "\n",
    "c_0_DNS = c[0, :]\n",
    "c_2_DNS = c[1, :]\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "for i, k in enumerate(index_train):\n",
    "    assert abs(c_0_DNS[k] - train_dataset[i][1][0].numpy()) < 0.000001, \"Training set for C0 differs from input values!\"\n",
    "    assert abs(c_2_DNS[k] - train_dataset[i][1][1].numpy()) < 0.000001, \"Training set for C2 differs from input values!\"\n",
    "for i, k in enumerate(index_test):\n",
    "    assert abs(c_0_DNS[k] - test_dataset[i][1][0].numpy()) < 0.000001, \"Test set for C0 differs from input values!\"\n",
    "    assert abs(c_2_DNS[k] - test_dataset[i][1][1].numpy()) < 0.000001, \"Test set for C2 differs from input values!\"\n",
    "    \n",
    "start_time = time.time()\n",
    "\n",
    "n_estimators = 512  #number of trees\n",
    "model_forest = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "model_forest.fit(X_train, y_train)\n",
    "preds = model_forest.predict(X_test)\n",
    "print(f\"{'time ML: '}{time.time()-start_time:.2e}\")\n",
    "\n",
    "c0 = preds[:, 0]\n",
    "c2 = preds[:, 1]\n",
    "c0_std = np.std(c0 - c_0_DNS[index_test]) / (np.mean(c0.flatten()**2))**0.5\n",
    "c2_std = np.std(c2 - c_2_DNS[index_test]) / (np.mean(c2.flatten()**2))**0.5\n",
    "\n",
    "print('\\nc0_error_std: ', c0_std)\n",
    "print('\\nc2_error_std: ', c2_std)\n",
    "\n",
    "#improvement in training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbulent zero-pressure gradient boundary layer\n",
    "\n",
    "For testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning data from: BoundaryLayer. Min yplus: 20. Max yplus: 2200\n",
      "Returning c = [c0, c2], a11 and a33\n",
      "\n",
      "c0_error_std:  0.2195137351790785\n",
      "\n",
      "c2_error_std:  0.14385877120689633\n"
     ]
    }
   ],
   "source": [
    "y_DNS, yplus_DNS, u_DNS, uu_DNS, vv_DNS, ww_DNS, uv_DNS, k_DNS, eps_DNS, dudy_DNS = GetInputData('BoundaryLayer', 20, 2200)\n",
    "c, a11_DNS, a33_DNS = GetC0andC2(k_DNS, eps_DNS, dudy_DNS, uu_DNS, vv_DNS, ww_DNS)\n",
    "\n",
    "c_0_DNS = c[0, :]\n",
    "c_2_DNS = c[1, :]\n",
    "\n",
    "y = c.transpose()\n",
    "tau_DNS = abs(k_DNS/eps_DNS)\n",
    "dudy_squared_DNS = (dudy_DNS**2)\n",
    "viscous_t = k_DNS**2/eps_DNS \n",
    "nu = 8.00000e-06 \n",
    "\n",
    "T = tau_DNS\n",
    "dudy_squared_DNS_scaled = dudy_squared_DNS*T**2\n",
    "dudy_DNS_inv = 1/dudy_DNS/T\n",
    "viscous_t_plus= viscous_t/nu\n",
    "\n",
    "dudy_squared_DNS_scaled = dudy_squared_DNS_scaled.reshape(-1,1)\n",
    "dudy_DNS_inv_scaled = dudy_DNS_inv.reshape(-1,1)\n",
    "yplus_DNS_scaled = yplus_DNS.reshape(-1,1)\n",
    "viscous_scaled = viscous_t_plus.reshape(-1,1)\n",
    "\n",
    "X=np.zeros((len(dudy_DNS),2))\n",
    "X[:,0] = scaler_dudy2.fit_transform(dudy_squared_DNS_scaled)[:,0]\n",
    "#X[:,1] = scaler_dudy.fit_transform(dudy_DNS_inv_scaled)[:,0]\n",
    "X[:,1] = scaler_yplus.fit_transform(yplus_DNS_scaled)[:,0]\n",
    "#X[:,2] = scaler_visc.fit_transform(viscous_scaled)[:,0]\n",
    "\n",
    "predictions_Boundary_forest = model_forest.predict(X)\n",
    "\n",
    "c_NN_forest = predictions_Boundary_forest\n",
    "\n",
    "c0=c_NN_forest[:,0]\n",
    "c2=c_NN_forest[:,1]\n",
    "c0_std=np.std(c0-c_0_DNS)/(np.mean(c0.flatten()**2))**0.5\n",
    "c2_std=np.std(c2-c_2_DNS)/(np.mean(c2.flatten()**2))**0.5\n",
    "\n",
    "print('\\nc0_error_std: ',c0_std)\n",
    "print('\\nc2_error_std: ',c2_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully developed plane turbulent channel flow $Re=550$  \n",
    "\n",
    "For testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning data from: FullyDevelopedChannel_Re550. Min yplus: 20. Max yplus: 2200\n",
      "Returning c = [c0, c2], a11 and a33\n",
      "\n",
      "c0_error_std:  79.35527293030806\n",
      "\n",
      "c2_error_std:  46.11007980321439\n"
     ]
    }
   ],
   "source": [
    "y_DNS, yplus_DNS, u_DNS, uu_DNS, vv_DNS, ww_DNS, uv_DNS, k_DNS, eps_DNS, dudy_DNS = GetInputData('FullyDevelopedChannel_Re550', 20, 2200)\n",
    "c, a11_DNS, a33_DNS = GetC0andC2(k_DNS, eps_DNS, dudy_DNS, uu_DNS, vv_DNS, ww_DNS)\n",
    "\n",
    "c_0_DNS = c[0, :]\n",
    "c_2_DNS = c[1, :]\n",
    "\n",
    "y = c.transpose()\n",
    "tau_DNS = abs(k_DNS/eps_DNS)\n",
    "dudy_squared_DNS = (dudy_DNS**2)\n",
    "viscous_t = k_DNS**2/eps_DNS \n",
    "nu = 8.00000e-06 \n",
    "\n",
    "T = tau_DNS\n",
    "dudy_squared_DNS_scaled = dudy_squared_DNS*T**2\n",
    "dudy_DNS_inv = 1/dudy_DNS/T\n",
    "viscous_t_plus= viscous_t/nu\n",
    "\n",
    "dudy_squared_DNS_scaled = dudy_squared_DNS_scaled.reshape(-1,1)\n",
    "dudy_DNS_inv_scaled = dudy_DNS_inv.reshape(-1,1)\n",
    "yplus_DNS_scaled = yplus_DNS.reshape(-1,1)\n",
    "viscous_scaled = viscous_t_plus.reshape(-1,1)\n",
    "\n",
    "X=np.zeros((len(dudy_DNS),2))\n",
    "X[:,0] = scaler_dudy2.fit_transform(dudy_squared_DNS_scaled)[:,0]\n",
    "#X[:,1] = scaler_dudy.fit_transform(dudy_DNS_inv_scaled)[:,0]\n",
    "X[:,1] = scaler_yplus.fit_transform(yplus_DNS_scaled)[:,0]\n",
    "#X[:,2] = scaler_visc.fit_transform(viscous_scaled)[:,0]\n",
    "\n",
    "predictions_channel_forest = model_forest.predict(X)\n",
    "\n",
    "c_NN_forest = predictions_channel_forest\n",
    "\n",
    "c0=c_NN_forest[:,0]\n",
    "c2=c_NN_forest[:,1]\n",
    "c0_std=np.std(c0-c_0_DNS)/(np.mean(c0.flatten()**2))**0.5\n",
    "c2_std=np.std(c2-c_2_DNS)/(np.mean(c2.flatten()**2))**0.5\n",
    "\n",
    "print('\\nc0_error_std: ',c0_std)\n",
    "print('\\nc2_error_std: ',c2_std)\n",
    "\n",
    "#Error is lower compared to our hand-coded Neural Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
